{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad0db803",
   "metadata": {},
   "source": [
    "# What Tone does Top Philosophers Talk Like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059a094f",
   "metadata": {},
   "source": [
    "## Project 1 by Christopher Halim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da96fb13",
   "metadata": {},
   "source": [
    "### The history of philosophy is very vast and wide-ranging. When we're taking about history, there are various ways we can perceive it. One can start to analyze the history of philosophy all the way back to BC time or the beginning of the 19th century. For my analysis, I am interested in exploring the way Philosophers change over time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a7a860",
   "metadata": {},
   "source": [
    "### My objective for this analysis to find out 2 different things: \n",
    "#### 1. Most widely used words/vocabulary, classifying them by author and school.\n",
    "#### 2. Which philosopheres have the most sentence length?\n",
    "#### 3. Finding the sentiment analysis for top 5 philosophers with the most sentence length. I aim to explore the different ways these philosophers write their own narrative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1e4795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a30134d",
   "metadata": {},
   "source": [
    "## First, we start our analysis by importing the dataset and exploring it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d730b813",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/christopherhalim888/Downloads/philosophy_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233ed0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f9ea46",
   "metadata": {},
   "source": [
    "### I decided to then see the occurences/frequency of each title, school, and author just to see the general distirbution of the data before proceeding further ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b4e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cat = ['title', 'author', 'school','corpus_edition_date']\n",
    "\n",
    "for f in features_cat:\n",
    "    plt.figure(figsize=(14,5))\n",
    "    df[f].value_counts().plot(kind='bar')\n",
    "    plt.title(f)\n",
    "    plt.grid()\n",
    "    plt.savefig(f+\".jpeg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2080c87c",
   "metadata": {},
   "source": [
    "### As we can see from the 3 graphs above, Aristotle has the most features in terms of author, while analytic and 1997 are the most in terms of school and corpus edition date respectively "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85ac276",
   "metadata": {},
   "source": [
    "## Objective 1: To answer my first objective, finding the most widely used words/vocabulary,and classifying them by author and school. I am going to use Word Cloud in order to achieve this goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d59673",
   "metadata": {},
   "source": [
    "### Classifying the words by school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390fef9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "schools = df.school.unique().tolist()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for sc in schools:\n",
    "    df_temp = df[df.school==sc]\n",
    "    \n",
    "    print('School = ', sc, ':')\n",
    "    \n",
    "    text = \" \".join(txt for txt in df_temp.sentence_lowered)\n",
    "    wordcloud = WordCloud(stopwords=stop_words, max_font_size=50, max_words=500,\n",
    "                          width = 600, height = 400,\n",
    "                          background_color=\"white\").generate(text)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(sc+\".jpeg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c83cca",
   "metadata": {},
   "source": [
    "### From here, we can see the most frequent words that come up from each author, classified by school"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd175611",
   "metadata": {},
   "source": [
    "### Classifying the words by author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa99644",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "authors = df.author.unique().tolist()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for au in authors:\n",
    "    df_temp = df[df.author == au]\n",
    "    \n",
    "    print('Authors = ', au)\n",
    "    \n",
    "    text = \" \".join(txt for txt in df_temp.sentence_lowered)\n",
    "    wordcloud = WordCloud(stopwords=stop_words, max_font_size=50, max_words=500,\n",
    "                          width = 600, height = 400,\n",
    "                          background_color=\"white\").generate(text)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(au+\".jpeg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811fa948",
   "metadata": {},
   "source": [
    "### From here, we can see the most frequent words that come up from each author, classified by authors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bce762",
   "metadata": {},
   "source": [
    "## Objective 2: Author and Title with the Most Sentence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6959aa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.groupby(by=['title','author','school'])['sentence_length'].count().nlargest(10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f6b6ed",
   "metadata": {},
   "source": [
    "### We can see from the result above that Aristotle, Plato, Lewis, Beauvoir, and Malebranche are 5 of the philosophers with the most sentence length in the data. I am going to focus on these 5 philosophers as I'm analyzing how does these philosophers create nuances in their writings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70183c67",
   "metadata": {},
   "source": [
    "## Objective 3: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a1b0a1",
   "metadata": {},
   "source": [
    "### I am using the nltk package in order to classify the sentiment as positive, negative, and neutral. Any polarity score that is above 0.5 is considered positive, below -0.5 is negative, and in between is neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2f8611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "def SentimentAnalysis(sentence):\n",
    "    sentiment_analyzer = SentimentIntensityAnalyzer() \n",
    "    polarity_score = sentiment_analyzer.polarity_scores(sentence)\n",
    "    \n",
    "    if polarity_score['compound'] >= 0.5:\n",
    "        return \"positive\"\n",
    "    elif polarity_score['compound'] <= -0.5 :\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f233993",
   "metadata": {},
   "source": [
    "### The analysis below is intended to create the proportion of positive, negative, and neutral words for the 5 chosen philosophers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fc2760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "def Analyzer(df, author):\n",
    "    start = perf_counter()\n",
    "    df1 = df [df['author'] == author] \n",
    "        \n",
    "    corpus = ''\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    neu = 0\n",
    "    \n",
    "    for result in df1['sentence_lowered']:\n",
    "        corpus += result\n",
    "    \n",
    "    for i in range (len(df1)):\n",
    "        sentiment = (SentimentAnalysis(df1['sentence_lowered'].iloc[i]))\n",
    "        if sentiment == \"positive\":\n",
    "            pos += 1\n",
    "        elif sentiment == \"negative\":\n",
    "            neg += 1\n",
    "        else:\n",
    "            neu += 1\n",
    "    \n",
    "    plt.figure(figsize = (7, 7))\n",
    "    plt.pie([pos, neg, neu], labels = ['Positive', 'Negative', 'Neutral'], colors = ['#ff9999','#66b3ff','#99ff99','#ffcc99'], autopct='%1.2f%%')\n",
    "    centre_circle = plt.Circle((0, 0), 0.70, fc='white')\n",
    "    fig = plt.gcf()\n",
    "    fig.gca().add_artist(centre_circle)\n",
    "    plt.title(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03095e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analyzer(df, 'Aristotle')\n",
    "plt.savefig('aristotle.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3324c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analyzer(df, 'Plato')\n",
    "plt.savefig('plato.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7603a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analyzer(df, 'Lewis')\n",
    "plt.savefig('lewis.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2a0f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analyzer(df, 'Beauvoir')\n",
    "plt.savefig('beauvoir.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a47aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analyzer(df, 'Malebranche')\n",
    "plt.savefig('malebranche.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09b2694",
   "metadata": {},
   "source": [
    "### As we can see in the pie charts above, Malebranche is the philosopher with the most proportion of positive words, while Beauvoir writes the most negative words. In addition, Lewis work has the most neutral proportion of words in comparison with the other 4 philosophers that have the most sentence length"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
